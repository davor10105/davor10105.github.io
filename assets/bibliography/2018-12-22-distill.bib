@article{10.1145/3649458,
author = {Vukadin, Davor and Afri\'{c}, Petar and \v{S}ili\'{c}, Marin and Dela\v{c}, Goran},
title = {Advancing Attribution-Based Neural Network Explainability through Relative Absolute Magnitude Layer-Wise Relevance Propagation and Multi-Component Evaluation},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3649458},
doi = {10.1145/3649458},
abstract = {Recent advancement in deep-neural network performance led to the development of new state-of-the-art approaches in numerous areas. However, the black-box nature of neural networks often prohibits their use in areas where model explainability and model transparency are crucial. Over the years, researchers proposed many algorithms to aid neural network understanding and provide additional information to the human expert. One of the most popular methods being Layer-Wise Relevance Propagation (LRP). This method assigns local relevance based on the pixel-wise decomposition of nonlinear classifiers. With the rise of attribution method research, there has emerged a pressing need to assess and evaluate their performance. Numerous metrics have been proposed, each assessing an individual property of attribution methods such as faithfulness, robustness, or localization. Unfortunately, no single metric is deemed optimal for every case, and researchers often use several metrics to test the quality of the attribution maps. In this work, we address the shortcomings of the current LRP formulations and introduce a novel method for determining the relevance of input neurons through layer-wise relevance propagation. Furthermore, we apply this approach to the recently developed Vision Transformer architecture and evaluate its performance against existing methods on two image classification datasets, namely ImageNet and PascalVOC. Our results clearly demonstrate the advantage of our proposed method. Furthermore, we discuss the insufficiencies of current evaluation metrics for attribution-based explainability and propose a new evaluation metric that combines the notions of faithfulness, robustness, and contrastiveness. We utilize this new metric to evaluate the performance of various attribution-based methods. Our code is available at:},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
articleno = {47},
numpages = {30},
keywords = {Explainable artificial intelligence, Vision Transformer, layer-wise relevance propagation, attribution-based evaluation}
}

@ARTICLE{9449663,
  author={Vukadin, Davor and Kurdija, Adrian Satja and Delač, Goran and Šilić, Marin},
  journal={IEEE Access}, 
  title={Information Extraction From Free-Form CV Documents in Multiple Languages}, 
  year={2021},
  volume={9},
  number={},
  pages={84559-84575},
  keywords={Hidden Markov models;Data mining;Natural language processing;Bit error rate;Solid modeling;Context modeling;Training;Information retrieval;natural language processing;text analysis;recurrent neural networks;CV parsing},
  doi={10.1109/ACCESS.2021.3087913}}

@misc{vukadin2025largelanguagemodelsattribution,
      title={Large Language Models as Attribution Regularizers for Efficient Model Training}, 
      author={Davor Vukadin and Marin Šilić and Goran Delač},
      year={2025},
      eprint={2502.20268},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.20268}, 
}

@INPROCEEDINGS{10569295,
  author={Vukadin, Davor and Šilić, Marin and Delač, Goran and Vladimir, Klemo},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Evaluating Harmony: Neural Network Explanation Metrics and Human Perception}, 
  year={2024},
  volume={},
  number={},
  pages={7-12},
  keywords={Measurement;Training;Location awareness;Codes;Computational modeling;Reinforcement learning;Robustness;Computer Vision;Neural Networks;Explainable Artificial Intelligence},
  doi={10.1109/MIPRO60963.2024.10569295}}


@ARTICLE{10035995,
  author={Afric, Petar and Vukadin, Davor and Silic, Marin and Delac, Goran},
  journal={IEEE Access}, 
  title={Empirical Study: How Issue Classification Influences Software Defect Prediction}, 
  year={2023},
  volume={11},
  number={},
  pages={11732-11748},
  keywords={Natural language processing;Computer bugs;Measurement;Data models;Predictive models;Complexity theory;Codes;Software quality;Issue tracking;version control systems;natural language processing;issue classification;software defect prediction;RoBERTa},
  doi={10.1109/ACCESS.2023.3242045}}

@INPROCEEDINGS{10159700,
  author={Džida, Mladen and Vukadin, Davor and Šilić, Marin and Delač, Goran and Vladimir, Klemo},
  booktitle={2023 46th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={An Overview of State-of-the-art Solutions for Scene Text Detection}, 
  year={2023},
  volume={},
  number={},
  pages={947-952},
  keywords={Image quality;Deep learning;Shape;Neural networks;Text detection;Benchmark testing;Real-time systems;Scene text;Text detection;Bounding box;Multioriented text;Segmentation;Convolutional neural networks},
  doi={10.23919/MIPRO57284.2023.10159700}}
