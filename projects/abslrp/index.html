<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> absLRP | Davor Vukadin </title> <meta name="author" content="Davor &lt;b&gt;Vukadin&lt;/b&gt;"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/horus_nobg.png?b2dca1ec74de6a5c354d6416c06044d9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://davor10105.github.io/projects/abslrp/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div style="margin-right:20px;"><img src="/assets/img/horus_nobg.png" height="32px"></div> <a class="navbar-brand title font-weight-lighter" href="/"> Davor Vukadin </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">absLRP</h1> <p class="post-description"></p> </header> <article> <h2 id="-visualize-vision-transformer-attribution-maps-and-more">ðŸ¤– Visualize Vision Transformer attribution maps and more!</h2> <p>This repository contains the source code for the new <strong>Absolute Magnitude Layer-Wise Relevance Propagation</strong> attribution method and the <strong>Global Evaluation Metric</strong> described in the paper https://dl.acm.org/doi/10.1145/3649458 .</p> <h2 id="-absolute-magnitude-layer-wise-relevance-propagation">ðŸ”Ž Absolute Magnitude Layer-Wise Relevance Propagation</h2> <p>A novel Layer-Wise Propagation rule, referred to as <strong>Abs</strong>olute Magnitude <strong>L</strong>ayer-Wise <strong>R</strong>elevance <strong>P</strong>ropagation (<strong>absLRP</strong>). This rule effectively addresses the issue of incorrect relative attribution between neurons within the same layer that exhibit varying absolute magnitude activations. We apply this rule to three different architectures, including the very recent Vision Transformer.</p> <p><img src="images/image-2.png" alt="Alt text"> <em>Figure 1. absLRP visualizations for Vision Transformer architecture - PascalVOC</em></p> <p><img src="images/image-1.png" alt="Alt text"> <em>Figure 2. absLRP visualizations for VGG architecture - ImageNet</em></p> <h3 id="-usage">ðŸ”¬ Usage</h3> <details> <summary>Import required modules</summary> ```python import torch from abslrp_gae.abslrp.rules.models import VGGAbsLRPRule, ResNetAbsLRPRule, VisionTransformerAbsLRPRule from abslrp_gae.abslrp.relevancy_methods import AbsLRPRelevancyMethod from abslrp_gae.utils import preprocess_image, visualize_batch import timm from timm.models.vision_transformer import VisionTransformer from PIL import Image ``` </details> <p>Load a model from <strong>timm</strong> and apply the <strong>absLRP</strong> rule:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load the model
</span><span class="n">device</span> <span class="o">=</span> <span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="p">.</span><span class="nf">create_model</span><span class="p">(</span><span class="sh">"</span><span class="s">vit_base_patch16_224</span><span class="sh">"</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># model = timm.create_model("vgg16", pretrained=True)
# model = timm.create_model("resnet50", pretrained=True)
</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># apply the absLRP rule to the model
</span><span class="nc">VisionTransformerAbsLRPRule</span><span class="p">().</span><span class="nf">apply</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="c1"># VGGAbsLRPRule().apply(model)
# ResNetAbsLRPRule().apply(model)
</span></code></pre></div></div> <p>Load inference images and preprocess:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">is_vit</span> <span class="o">=</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">VisionTransformer</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="nf">preprocess_image</span><span class="p">(</span><span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">images/dog_cat.jpeg</span><span class="sh">"</span><span class="p">),</span> <span class="n">is_vit</span><span class="p">),</span>
        <span class="nf">preprocess_image</span><span class="p">(</span><span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">images/hedgehog.jpg</span><span class="sh">"</span><span class="p">),</span> <span class="n">is_vit</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div> <p>Calculate contrastive relevance using absLRP and visualize:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">relevancy_method</span> <span class="o">=</span> <span class="nc">AbsLRPRelevancyMethod</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">relevance</span> <span class="o">=</span> <span class="n">relevancy_method</span><span class="p">.</span><span class="nf">relevancy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nf">visualize_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">relevance</span><span class="p">,</span> <span class="n">is_vit</span><span class="p">)</span>
</code></pre></div></div> <center> ![Usage absLRP example output](images/example_image.png) </center> <h2 id="-global-evaluation-metric">ðŸ“Š Global Evaluation Metric</h2> <p>A new evaluation method, Global Attribution Evaluation (GAE), which offers a novel perspective on evaluating faithfulness and robustness of an attribution method by utilizing gradient-based masking, while combining those results with a localization method to achieve a comprehensive evaluation of explanation quality in a single score.</p> <p><img src="images/image-4.png" alt="Alt text"> <em>Figure 3. Top and bottom 5 scoring images on GAE metric out of a randomly sampled 1024 images - absLRP VGG ImageNet</em></p> <h3 id="-usage-1">ðŸ”¬ Usage</h3> <p>Import the required libraries</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">abslrp_gae.gae.gae</span> <span class="kn">import</span> <span class="n">GlobalEvaluationMetric</span>
</code></pre></div></div> <p>Define a dictionary of relevancy methods:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">relevancy_methods</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">abslrp</span><span class="sh">"</span><span class="p">:</span> <span class="n">relevancy_method</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <p>Run the metric</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metric</span> <span class="o">=</span> <span class="nc">GlobalEvaluationMetric</span><span class="p">()</span>
<span class="n">metric</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span>
    <span class="n">relevancy_methods</span><span class="o">=</span><span class="n">relevancy_methods</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">base_model</span><span class="p">,</span> <span class="c1"># original model
</span>    <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></div> <p>Plot the results</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">metric</span><span class="p">.</span><span class="nf">plot</span><span class="p">()</span>
</code></pre></div></div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Davor <b>Vukadin</b>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>